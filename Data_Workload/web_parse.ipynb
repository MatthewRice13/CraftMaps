{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "import re, time\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from difflib import SequenceMatcher\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links used\n",
    "ratebeer_Ireland_URL = \"https://www.ratebeer.com/breweries/ireland/0/100/#closed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "## scraping tool\n",
    "# get data from links\n",
    "def make_soup(url_linker):\n",
    "    # impose scrape padding\n",
    "    time.sleep(0.5)\n",
    "    req = requests.get(url_linker)\n",
    "    data = req.text\n",
    "    soup = BeautifulSoup(data,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "########################\n",
    "## parsing & cleaning\n",
    "# gets table data\n",
    "def parse_table(URLi, size):\n",
    "    print(\"Starting...\")\n",
    "    page = make_soup(URLi)\n",
    "    page_table = page.find_all('table')[0]\n",
    "    # data\n",
    "    data = []\n",
    "    count = 0\n",
    "    for i, li in enumerate(page_table.select('tr')):\n",
    "        if count > size:\n",
    "            break\n",
    "        else:\n",
    "            count = count+1\n",
    "        # gets other data\n",
    "        txt = str(i)\n",
    "        for d in li.select('td'):\n",
    "            if \"<br/>\" in str(d):\n",
    "                fresh = str(d).split(\"<br/>\")\n",
    "                brewery_name = BeautifulSoup(fresh[0],\"html.parser\").text\n",
    "                brewery_region = re.split(\" - \", BeautifulSoup(fresh[1],\"html.parser\").text)[0]\n",
    "            else:\n",
    "                txt = txt + \", \" + re.sub(\"\\s\\s+\",\" \",d.text)\n",
    "        # gets url\n",
    "        for ab in li.select('a'):\n",
    "            url_data = get_brewery_url(ab['href'],brewery_name)\n",
    "            break\n",
    "        # skip empty value\n",
    "        # clean data\n",
    "        if i!=0:\n",
    "            # formats into array\n",
    "            brewery_type = str(txt).split(\", \")\n",
    "            # accounts for dirt\n",
    "            if \"rew\" not in brewery_type[0]:\n",
    "                loc = find_brew_type(brewery_type)\n",
    "                brewery_type = brewery_type[loc]\n",
    "            # creats dict\n",
    "            context = {\n",
    "                'name':brewery_name, \n",
    "                'region':brewery_region,\n",
    "                'type':brewery_type,\n",
    "                'url':url_data['url'],\n",
    "                'twitter':url_data['twitter'],\n",
    "                'facebook':url_data['facebook']\n",
    "            }\n",
    "            # adds to data\n",
    "            data.append(context)\n",
    "            \n",
    "    print(\"table data: done...\")\n",
    "    return data\n",
    "\n",
    "# gets brewery url\n",
    "def get_brewery_url(url_ending, brew_name):\n",
    "    time.sleep(0.5)\n",
    "    data = []\n",
    "    url_brews = \"https://www.ratebeer.com\"\n",
    "    work_url = url_brews+url_ending\n",
    "    # clean name\n",
    "    brew_name = re.sub(\" \",\"\",str(brew_name))\n",
    "    brew_name = re.sub(\"-\",\"\",str(brew_name))\n",
    "    brew_name = re.sub(\"Brewery\",\"\",str(brew_name))\n",
    "    # get urls\n",
    "    links_list = make_soup(work_url).find_all('a')\n",
    "    # break url\n",
    "    url_boolean = False\n",
    "    twitter_boolean = False\n",
    "    facebook_boolean = False\n",
    "    final_boolean = False\n",
    "    # loop through all links\n",
    "    for link in links_list:\n",
    "        # gets link\n",
    "        lk = link.get('href')\n",
    "        # break when all found\n",
    "        if url_boolean and twitter_boolean and facebook_boolean == True:\n",
    "            break\n",
    "        # strips noise\n",
    "        lk = re.sub(\"www.\",\"\",str(lk))\n",
    "        lk = re.sub(\"https://\",\"\",str(lk))\n",
    "        lk = re.sub(\"http://\",\"\",str(lk))\n",
    "        lk = re.sub(\" \",\"\",str(lk))\n",
    "        # define url sets\n",
    "        url_ending_set = ['brewing.ie','brewing.com','brewery.com','brewery.ie','beer.com','beer.ie','.com','.ie']\n",
    "        social_ending_set = ['','brew','brewery','brewing','beer','craft','brewing']\n",
    "        # main url\n",
    "        if url_boolean == False:\n",
    "            #site_url = str(\"www.\"+brew_name+\".ie\")\n",
    "            site_url = str(\"www.google.com\")\n",
    "            # loop through possible endings\n",
    "            for ending in url_ending_set:\n",
    "                # check brew name to find url\n",
    "                check_this_url = str(brew_name+ending)\n",
    "                if url_similarity(check_this_url, str(lk)) > 0.75:\n",
    "                    site_url = lk\n",
    "                    url_boolean = True\n",
    "                    break        \n",
    "        # Twitter\n",
    "        if twitter_boolean == False:\n",
    "            twitter_site_call = \"twitter.com\"\n",
    "            #twitter_url = str(\"www.\"+twitter_site_call+\"/\"+brew_name)\n",
    "            twitter_url = str(\"www.twitter.com\")\n",
    "            # loop through possible endings\n",
    "            for ending in social_ending_set:\n",
    "                # check brew name to find url\n",
    "                check_this_url = str(twitter_site_call+\"/\"+brew_name+\"\"+ending+\"\")\n",
    "                if url_similarity(check_this_url, str(lk)) > 0.9:\n",
    "                    twitter_url = lk\n",
    "                    twitter_boolean = True\n",
    "                    break\n",
    "        # Facebook\n",
    "        if facebook_boolean == False:\n",
    "            facebook_site_call = \"facebook.com\"\n",
    "            #facebook_url = str(\"www.\"+facebook_site_call+\"/\"+brew_name)\n",
    "            facebook_url = str(\"www.facebook.com\")\n",
    "            # loop through possible endings\n",
    "            for ending in social_ending_set:\n",
    "                # check brew name to find url\n",
    "                check_this_url = str(facebook_site_call+\"/\"+brew_name+\"\"+ending+\"\")\n",
    "                if url_similarity(check_this_url, str(lk)) > 0.9:\n",
    "                    facebook_url = lk\n",
    "                    facebook_boolean = True\n",
    "                    break\n",
    "                    \n",
    "    # create dictionary for return\n",
    "    url_content = {\n",
    "        'url':site_url,\n",
    "        'twitter':twitter_url,\n",
    "        'facebook':facebook_url\n",
    "    }\n",
    "    return url_content\n",
    "\n",
    "\n",
    "###########################\n",
    "## cleaning methods\n",
    "# url similarity measure\n",
    "def url_similarity(url_a, url_b):\n",
    "    return SequenceMatcher(None, url_a, url_b).ratio()\n",
    "\n",
    "# cleans address\n",
    "def parseAddress(address):\n",
    "    return re.sub(\"\\s\\s+\",\"\", re.sub('\"','', re.sub('\"langaddress\": ','',address)))\n",
    "\n",
    "# coverts string to float\n",
    "def parseFloat(digit):\n",
    "    rtn_flo = re.findall(\"\\d+\\.\\d+\", digit)\n",
    "    if len(rtn_flo)>=1:\n",
    "        rtn = rtn_flo[0]\n",
    "    else:\n",
    "        rtn = 0.0\n",
    "    return float(rtn)\n",
    "\n",
    "# removes unwanted data from html\n",
    "def find_between(s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "\n",
    "# gets type from array\n",
    "def find_brew_type(look_up):\n",
    "    value = 0\n",
    "    for i,d in enumerate(look_up):\n",
    "        if \"rew\" in d:\n",
    "            value = i\n",
    "    return value\n",
    "\n",
    "#########################\n",
    "# creates dictionary\n",
    "def pull_data(new_str):\n",
    "    ads = \"none\"\n",
    "    lon = 0.0\n",
    "    lat = 0.0\n",
    "    \n",
    "    for i, d in enumerate(new_str.split(\"\\n\")):\n",
    "        if \"langaddress\" in d:\n",
    "            ads = parseAddress(d)\n",
    "            \n",
    "        if \"lon\" in d:\n",
    "            lon = parseFloat(d)\n",
    "            \n",
    "        if \"lat\" in d:\n",
    "            lat = parseFloat(d)\n",
    "            \n",
    "    # create dict\n",
    "    content = {\n",
    "        \"address\":ads,\n",
    "        \"long\": lon,\n",
    "        \"lati\": lat\n",
    "    }\n",
    "    \n",
    "    # return\n",
    "    return content\n",
    "\n",
    "def get_loc(name,area):\n",
    "    from googleplaces import GooglePlaces, types, lang\n",
    "    YOUR_API_KEY = \"AIzaSyDFK8QRiUl8jx5YYQwDMQ31GMyXwXz-et8\"\n",
    "    google_places= GooglePlaces(YOUR_API_KEY)\n",
    "    query_result = google_places.nearby_search(\n",
    "            location= str(area) + ', Ireland', \n",
    "            keyword = str(name),\n",
    "            radius  = 25000\n",
    "    )\n",
    "    content = None\n",
    "    for place in query_result.places:\n",
    "        loc_data = place.geo_location\n",
    "    for place in query_result.places:\n",
    "        if place.name is None:\n",
    "            # create dict\n",
    "            content = {\n",
    "                \"address\": place.name+\",\"+area+\",Ireland\",\n",
    "                \"long\": loc_data['lng'],\n",
    "                \"lati\": loc_data['lat']\n",
    "            }\n",
    "        break\n",
    "    # return\n",
    "    return content\n",
    "        \n",
    "########################\n",
    "# data entry prep\n",
    "# gets long lats from nominatim\n",
    "def make_data(url_link):\n",
    "    url_link = url_link.replace(\" \", \"+\")\n",
    "    page = make_soup(url_link)\n",
    "    section = page.find_all('script')[0]\n",
    "    data = find_between(str(section),\"var nominatim_results = [\",\"\\\"importance\") + \" }\"\n",
    "    return data\n",
    "\n",
    "# cleans and formats\n",
    "def complete_data(size):\n",
    "    count = 0\n",
    "    # url formating\n",
    "    site_url = \"https://nominatim.openstreetmap.org/search.php?q=\"\n",
    "    country = \"Ireland\"\n",
    "    ending = \"&polygon_geojson=1&viewbox=\"\n",
    "    spacing = \"%2C\"\n",
    "    \n",
    "    # parse table data\n",
    "    table_data = parse_table(ratebeer_Ireland_URL, size)\n",
    "    # data entry\n",
    "    brew_data = []\n",
    "    for z,d in enumerate(table_data):\n",
    "        # testing\n",
    "        if z%5==0:\n",
    "           time.sleep(1.5)\n",
    "        # gather data\n",
    "        brewery_name = d['name']\n",
    "        brewery_town = re.split(\" - \",d['region'])[0]\n",
    "        brewery_type = d['type']\n",
    "        brewery_URL = d['url']\n",
    "        brewery_twitter = d['twitter'],\n",
    "        brewery_facebook = d['facebook']\n",
    "        \n",
    "        cut_data = get_loc(brewery_name,brewery_town)\n",
    "        if cut_data is None:\n",
    "            # create failsafe\n",
    "            URLA = site_url+brewery_name+brewery_town+spacing+country+ending\n",
    "            URLB = site_url+brewery_town+spacing+country+ending\n",
    "            newSTR = make_data(URLA)\n",
    "            # check urls\n",
    "            if len(newSTR) < 5:\n",
    "                newSTR = make_data(URLB)\n",
    "                cut_data = pull_data(newSTR)\n",
    "            else:\n",
    "                cut_data = pull_data(newSTR)\n",
    "            \n",
    "        address_data = cut_data['address'].split(\",\")\n",
    "        # create dict for db entry\n",
    "        model_dictionary = {\n",
    "            'name':brewery_name,\n",
    "            'region':address_data[0],\n",
    "            'address':cut_data['address'],\n",
    "            'type':brewery_type,\n",
    "            'lati':cut_data['lati'],\n",
    "            'long':cut_data['long'],\n",
    "            'url':brewery_URL,\n",
    "            'twitter':brewery_twitter,\n",
    "            'facebook':brewery_facebook,\n",
    "            'tour':True,\n",
    "            'merch':True\n",
    "        }\n",
    "        # creates dict\n",
    "        brew_data.append(model_dictionary)\n",
    "    # return\n",
    "    print(\"complete data: done...\")\n",
    "    return brew_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "table data: done...\n",
      "complete data: done...\n"
     ]
    }
   ],
   "source": [
    "brew_data = complete_data(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'...finished writing data.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_file(data):\n",
    "    wr_file = open('json_data_base.txt', 'w')\n",
    "    for d in data:\n",
    "        wr_file.write(str(d)+\"\\n\")\n",
    "    wr_file.close()\n",
    "    return \"...finished writing data.\"\n",
    "    \n",
    "write_file(brew_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
